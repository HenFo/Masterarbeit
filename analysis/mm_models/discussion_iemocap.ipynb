{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import my_utils as utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BASE_PATH_CONCAT = os.path.join(\"results\", \"early_concat\")\n",
    "BASE_PATH_FUSION = os.path.join(\"results\", \"late_fusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IEMOCAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"IEMOCAP\"\n",
    "\n",
    "\n",
    "def get_result_dataframe(dataset: str) -> pd.DataFrame:\n",
    "    fusion_path = os.path.join(BASE_PATH_FUSION, dataset, \"preds_test.json\")\n",
    "    fusion_audio_path = os.path.join(\n",
    "        BASE_PATH_FUSION, dataset, \"preds_test_no_text.json\"\n",
    "    )\n",
    "    concat_path = os.path.join(BASE_PATH_CONCAT, dataset, \"preds_test_normal.json\")\n",
    "    concat_audio_path = os.path.join(\n",
    "        BASE_PATH_CONCAT, dataset, \"preds_test_audio_only.json\"\n",
    "    )\n",
    "\n",
    "    fusion_df = utils.build_result_dataframe(fusion_path)\n",
    "    fusion_audio_df = utils.build_result_dataframe(fusion_audio_path)\n",
    "    concat_df = utils.build_result_dataframe(concat_path)\n",
    "    concat_audio_df = utils.build_result_dataframe(concat_audio_path)\n",
    "\n",
    "    assert len(fusion_df) == len(concat_df)\n",
    "\n",
    "    results = utils.merge_result_dataframes(\n",
    "        [fusion_df, concat_df, fusion_audio_df, concat_audio_df],\n",
    "        [\"fusion\", \"concat\", \"fusion_audio\", \"concat_audio\"],\n",
    "    )\n",
    "    results = utils.extract_dialogue_information(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "df = get_result_dataframe(DATASET)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"target\"].value_counts().index.to_list()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "iemocap_positive_emotions = [\"happy\", \"excited\"]\n",
    "iemocap_negative_emotions = [\"angry\", \"sad\", \"frustrated\"]\n",
    "\n",
    "\n",
    "iemocap_classify_sentiment = partial(\n",
    "    utils.classify_sentiment,\n",
    "    positive=iemocap_positive_emotions,\n",
    "    negative=iemocap_negative_emotions,\n",
    ")\n",
    "\n",
    "df[\"emotion_sentiment\"] = df[\"target\"].apply(iemocap_classify_sentiment)\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"emotion_sentiment\", \"target\", \"utterance\"],\n",
    "    value_vars=[\"output\", \"output_concat\"],\n",
    "    var_name=\"source\",\n",
    "    value_name=\"output_long\",\n",
    ")\n",
    "df_long[\"emotion_sentiment_prediction\"] = df_long[\"output_long\"].apply(\n",
    "    iemocap_classify_sentiment\n",
    ")\n",
    "\n",
    "\n",
    "utils.print_confusion_matrix(\n",
    "    df_long,\n",
    "    target_labels=[\"positive\", \"negative\"],\n",
    "    output_column=\"emotion_sentiment_prediction\",\n",
    "    target_column=\"emotion_sentiment\",\n",
    "    xlab_name=\"Predicted Sentiment\",\n",
    "    ylab_name=\"True Sentiment\",\n",
    "    text_size=28,\n",
    "    label_scaling_adjustment=4,\n",
    "    name=\"images/sentiment_iemocap_cm.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_confusion_matrix(\n",
    "    df_long,\n",
    "    target_labels=iemocap_negative_emotions,\n",
    "    output_column=\"output_long\",\n",
    "    target_column=\"target\",\n",
    "    text_size=20,\n",
    "    label_scaling_adjustment=2,\n",
    "    name=\"images/negative_iemocap_cm.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_confusion_matrix(\n",
    "    df_long,\n",
    "    target_labels=iemocap_positive_emotions,\n",
    "    output_column=\"output_long\",\n",
    "    target_column=\"target\",\n",
    "    text_size=28,\n",
    "    label_scaling_adjustment=4,\n",
    "    name=\"images/positive_iemocap_cm.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_audio = df.melt(\n",
    "    id_vars=[\"emotion_sentiment\", \"target\", \"utterance\"],\n",
    "    value_vars=[\"output_fusion_audio\", \"output_concat_audio\"],\n",
    "    var_name=\"source\",\n",
    "    value_name=\"output_long\",\n",
    ")\n",
    "df_long_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_confusion_matrix(\n",
    "    df_long_audio,\n",
    "    target_labels=labels[::-1],\n",
    "    output_column=\"output_long\",\n",
    "    target_column=\"target\",\n",
    "    title=\"Confusion Matrix (Audio)\",\n",
    ")\n",
    "utils.print_confusion_matrix(\n",
    "    df_long,\n",
    "    target_labels=labels[::-1],\n",
    "    output_column=\"output_long\",\n",
    "    target_column=\"target\",\n",
    "    title=\"Confusion Matrix (Combined)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_confusion_matrix(\n",
    "    df_long_audio,\n",
    "    target_labels=[\"excited\", \"happy\"],\n",
    "    output_column=\"output_long\",\n",
    "    target_column=\"target\",\n",
    "    title=\"Confusion Matrix (Audio)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    import re\n",
    "    results = []\n",
    "    lines = text.strip().split('\\n')\n",
    "    # Remove any empty lines or lines that are just whitespace\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line.startswith('['):\n",
    "            # Start of a new block\n",
    "            if current_block:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "            current_block.append(line)\n",
    "        else:\n",
    "            current_block.append(line)\n",
    "    if current_block:\n",
    "        blocks.append(current_block)\n",
    "    \n",
    "    # Function to parse the header line and extract the target emotion label\n",
    "    def parse_header(header):\n",
    "        # Assuming header format is:\n",
    "        # [START_TIME - END_TIME] TURN_NAME EMOTION [V, A, D]\n",
    "        # We can use regex to extract the EMOTION\n",
    "        pattern = r'^\\[.*?\\]\\s+(.*?)\\s+(.*?)\\s+\\[.*?\\]$'\n",
    "        match = re.match(pattern, header)\n",
    "        if match:\n",
    "            turn_name = match.group(1)\n",
    "            emotion = match.group(2)\n",
    "            return emotion\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    for block in blocks:\n",
    "        # Process each block\n",
    "        # The first line is the header line\n",
    "        header = block[0]\n",
    "        emotion = parse_header(header)\n",
    "        if emotion is None:\n",
    "            continue\n",
    "        target = emotion\n",
    "        # Initialize annotations list\n",
    "        annotations = []\n",
    "        for line in block[1:]:\n",
    "            if line.startswith('C-'):\n",
    "                # Extract the labels\n",
    "                # Format is \"C-E1:    Excited;    ()\"\n",
    "                label_line = line.split(':',1)[1]  # Get the part after the colon\n",
    "                label_line = label_line.strip()\n",
    "                # Remove the '()' at the end if present\n",
    "                if label_line.endswith('()'):\n",
    "                    label_line = label_line[:-2].strip()\n",
    "                # Now, labels are separated by semicolons\n",
    "                labels = label_line.split(';')\n",
    "                # Remove empty strings and strip spaces\n",
    "                labels = [label.strip() for label in labels if label.strip()]\n",
    "                annotations.extend(labels)\n",
    "        result = {\"target\": target, \"annotations\": annotations}\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "emo_eval = glob(\"../../datasets/iemocap/IEMOCAP_full_release/Session*/dialog/EmoEvaluation/*.txt\")\n",
    "data = []\n",
    "\n",
    "for emo_eval_file in emo_eval:\n",
    "    with open(emo_eval_file) as f:\n",
    "        text = f.read()\n",
    "        processed = process_text(text)\n",
    "        dialogue = emo_eval_file.split('/')[-1].split('.')[0]\n",
    "        processed = list(map(lambda x: {**x, \"dialogue\": dialogue}, processed))\n",
    "        data.extend(processed)\n",
    "\n",
    "data = pd.DataFrame.from_records(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"target\"] == \"hap\"][\"annotations\"].apply(lambda x: x.count(\"Excited\")).sum() / len(data[data[\"target\"] == \"hap\"])\n",
    "data[data[\"target\"] == \"exc\"][\"annotations\"].apply(lambda x: x.count(\"Happiness\")).sum() / len(data[data[\"target\"] == \"exc\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model = df[\"target\"] == df[\"output\"] \n",
    "concat_model = df[\"target\"] == df[\"output_concat\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df[\"any_correct\"] = df[\"target\"]\n",
    "df.loc[~fusion_model & ~concat_model, \"any_correct\"] = df[~fusion_model & ~concat_model][\"output\"]\n",
    "f1_score(df[\"target\"], df[\"any_correct\"], labels=labels, average=\"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_confusion_matrix_difference(df, target_labels=labels[::-1], output_column1=\"output\", output_column2=\"output_concat\", name = \"images/discussion_iemocap_diff_cm.png\", title=\"Confusion Matrix difference on IEMOCAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "\n",
    "\n",
    "def iou(df, label_true, label_pred=None):\n",
    "    label_pred = label_pred if label_pred is not None else label_true\n",
    "    diff = len(df[(df[\"target\"] == label_true) & (df[\"output\"] == label_pred)]) - len(\n",
    "        df[(df[\"target\"] == label_true) & (df[\"output_concat\"] == label_pred)]\n",
    "    )\n",
    "    inter = df[\n",
    "        (df[\"target\"] == label_true) & (df[\"output\"] == label_pred)\n",
    "    ].index.intersection(\n",
    "        df[(df[\"target\"] == label_true) & (df[\"output_concat\"] == label_pred)].index\n",
    "    )\n",
    "    union = df[(df[\"target\"] == label_true) & (df[\"output\"] == label_pred)].index.union(\n",
    "        df[(df[\"target\"] == label_true) & (df[\"output_concat\"] == label_pred)].index\n",
    "    )\n",
    "\n",
    "    numerator = len(inter)\n",
    "    denominator = len(union)\n",
    "    denominator_norm = len(union) - abs(diff)\n",
    "    result_iou = numerator / denominator if denominator != 0 else np.nan\n",
    "    result_norm = numerator / denominator_norm if denominator_norm != 0 else np.nan\n",
    "    return {\"iou\": result_iou, \"agreement\": result_norm, \"denominator\": denominator_norm, \"numerator\": numerator}\n",
    "\n",
    "\n",
    "cm_iou, cm_agreement = [], []\n",
    "for label_true in labels:\n",
    "    preds_iou, preds_agreement = [], []\n",
    "    for label_pred in labels:\n",
    "        r = iou(df, label_true, label_pred)\n",
    "        preds_iou.append(r[\"denominator\"])\n",
    "        preds_agreement.append(r[\"agreement\"])\n",
    "    cm_iou.append(preds_iou)\n",
    "    cm_agreement.append(preds_agreement)\n",
    "\n",
    "\n",
    "melted_iou = utils._prepare_confusion_matrix(cm_iou, labels).merge(\n",
    "    utils._prepare_confusion_matrix(cm_agreement, labels),\n",
    "    on=[\"actual\", \"predicted\"],\n",
    "    suffixes=[\"_iou\", \"_agreement\"],\n",
    ")\n",
    "melted_iou[\"label\"] = (\n",
    "    (melted_iou[\"count_agreement\"] * 100).round(1).astype(str)\n",
    "    + \"\\n(\"\n",
    "    + (melted_iou[\"count_iou\"]).round(1).astype(str) + \")\"\n",
    ")\n",
    "melted_iou\n",
    "\n",
    "p = (\n",
    "    ggplot(melted_iou, aes(\"factor(predicted)\", \"factor(actual)\", fill=\"count_agreement * 100\"))\n",
    "    + geom_tile(show_legend=True, width=0.98, height=0.98)\n",
    "    + geom_text(aes(label=\"label\"), size=16, show_legend=False, color = \"white\")\n",
    "    + ggtitle(\"Agreement Matrix IEMOCAP\")\n",
    "    + ylab(\"True Emotion\")\n",
    "    + xlab(\"Predicted Emotion\")\n",
    "    + scale_y_discrete(limits=labels[::-1])\n",
    "    + scale_fill_gradient2(low=\"#DC3440\", mid = \"#FFC685\", high=\"#1fae08\", limits=[0, 100], midpoint=60)\n",
    "    + theme_bw()\n",
    "    + guides(fill=\"none\")\n",
    "    + theme(\n",
    "        title=element_text(size=18),  # Increases title size\n",
    "        axis_title=element_text(\n",
    "            size=20\n",
    "        ),  # Increases axis title size\n",
    "        axis_text=element_text(\n",
    "            size=16\n",
    "        ),  # Increases axis tick label size\n",
    "        axis_text_x=element_text(rotation=45),  # Rotates x-axis tick labels\n",
    "    )\n",
    ")\n",
    "p.show()\n",
    "p.save(\"images/discussion_iemocap_agreement.png\", width=7, height=7, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou(df, \"frustrated\", \"neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_model = df[\"target\"] == df[\"output_concat\"]\n",
    "fusion_model = df[\"target\"] == df[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_confusion_matrix(\n",
    "    df[~concat_model & ~fusion_model],\n",
    "    target_labels=labels[::-1],\n",
    "    output_column=\"output\",\n",
    "    target_column=\"output_concat\",\n",
    "    xlab_name=\"Fusion Prediction\",\n",
    "    ylab_name=\"Concat Prediction\",\n",
    "    title=\"False-Prediction Agreement\",\n",
    "    show_percentage=False,\n",
    "    name=\"images/discussion_iemocap_false_prediction_agreement.png\",\n",
    "    text_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "for label in labels:\n",
    "    y_true = df[\"target\"].apply(lambda x: 1 if x == label else 0)\n",
    "    y_pred_fusion = df[\"output\"].apply(lambda x: 1 if x == label else 0)\n",
    "    y_pred_concat = df[\"output_concat\"].apply(lambda x: 1 if x == label else 0)\n",
    "\n",
    "    pre_label = precision_score(y_true, y_pred_fusion) * 100\n",
    "    rec_label = recall_score(y_true, y_pred_fusion) * 100\n",
    "    pre_label_ierc = precision_score(y_true, y_pred_concat) * 100\n",
    "    rec_label_ierc = recall_score(y_true, y_pred_concat) * 100\n",
    "    f1_fusion = f1_score(y_true, y_pred_fusion) * 100\n",
    "    f1_concat = f1_score(y_true, y_pred_concat) * 100\n",
    "    \n",
    "    print(f\"F1-score\\t für Label {label}: Fusion: {f1_fusion:.2f} - Concat: {f1_concat:.2f} - Different: {(f1_fusion - f1_concat):.2f}\")\n",
    "    print(f\"Precision\\t für Label {label}: Fusion: {pre_label:.2f} - Concat: {pre_label_ierc:.2f} - Differenz: {(pre_label - pre_label_ierc):.2f}\")\n",
    "    print(f\"Recall\\t\\t für Label {label}: Fusion: {rec_label:.2f} - Concat: {rec_label_ierc:.2f} - Differenz: {(rec_label - rec_label_ierc):.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weitere Statistiken\n",
    "Hier werden weitere Statistiken genannt, wie das Klassifizierungsverhalten der einzelnen Teilmodelle ist.\n",
    "Es wurden einmal die Ergebnisse von InstructERC, dem Late-Fusion Modell audio output, und dem kombinierten Modell berechnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. late-fusion Model (F)\n",
    "df_F = df[fusion_model]\n",
    "print(f\"In total, {len(df_F)} samples were recognized by the late-fusion model.\")\n",
    "\n",
    "# 3. concat Model (C)\n",
    "df_C = df[concat_model]\n",
    "print(f\"In total, {len(df_C)} samples were recognized by the concat model.\")\n",
    "\n",
    "\n",
    "# 5. NOT late-fusion Model (¬F)\n",
    "df_not_F = df[not_fusion_model]\n",
    "print(f\"In total, {len(df_not_F)} samples were NOT recognized by the late-fusion model.\")\n",
    "\n",
    "# 6. NOT concat Model (¬C)\n",
    "df_not_C = df[not_concat_model]\n",
    "print(f\"In total, {len(df_not_C)} samples were NOT recognized by the concat model.\")\n",
    "\n",
    "\n",
    "# 9. late-fusion AND concat Models (F ∧ C)\n",
    "df_F_and_C = df[fusion_model & concat_model]\n",
    "print(f\"In total, {len(df_F_and_C)} samples were recognized by both the late-fusion and concat models.\")\n",
    "\n",
    "\n",
    "# 13. late-fusion AND NOT concat Models (F ∧ ¬C)\n",
    "df_F_and_not_C = df[fusion_model & not_concat_model]\n",
    "print(f\"In total, {len(df_F_and_not_C)} samples were recognized by the late-fusion model but NOT by the concat model.\")\n",
    "\n",
    "\n",
    "# 15. concat AND NOT late-fusion Models (C ∧ ¬F)\n",
    "df_C_and_not_F = df[concat_model & not_fusion_model]\n",
    "print(f\"In total, {len(df_C_and_not_F)} samples were recognized by the concat model but NOT by the late-fusion model.\")\n",
    "\n",
    "\n",
    "# 18. NOT late-fusion AND NOT concat Models (¬F ∧ ¬C)\n",
    "df_not_F_and_not_C = df[not_fusion_model & not_concat_model]\n",
    "print(f\"In total, {len(df_not_F_and_not_C)} samples were NOT recognized by both the late-fusion and concat models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
